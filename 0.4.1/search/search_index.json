{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"SQLAlchemyCsvWriter","text":"<p>SQLAlchemyCsvWriter is a thin wrapper around the python csw.writer function to make the process of exporting SQLAlchemy query results to csv simpler. </p> <p>It supports both synchronous as well as asynchronous query results, as well as streaming.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Write SQLAlchemy query results to csv file with little boilerplate</li> <li>Optionally write header by auto generation or passing column names</li> <li>Supports same dialect and formatting parameters as csv.writer</li> <li>Supports synchronous, asynchronous and asynchronous streaming results</li> <li>Supports any models defined wit DeclarativeBase</li> </ul>"},{"location":"#installation","title":"Installation","text":"<ul> <li>with pip: <code>pip install sqlalchemy-csv-writer</code></li> <li>with poetry: <code>poetry add sqlalchemy-csv-writer</code></li> </ul>"},{"location":"#usage","title":"Usage","text":"<pre><code>from sqlalchemy_csv_writer import SQLAlchemyCsvWriter\n\nwith SQLAlchemyCsvWriter(\n    \"test.csv\",\n    header=True,\n    field_formats={\"column_1\": \"%.2f\"},\n    prefix_model_names=True,\n    dialect=\"unix\",\n) as writer:\n    writer.write_rows(results)  # pass results of SQLAlchemy query\n</code></pre> <p>For full example see examples directory (uses the alchemical SQLAlchemy wrapper).</p>"},{"location":"#development-nots","title":"Development Nots","text":"<ul> <li>Linting and formatting using ruff</li> <li>Testing using pytest</li> <li>Dependency management and release using poetry</li> <li>Documentation using mkdocs with mkdocs-material and other plugins, released to GitHub pages</li> <li>CI/CD using GitHub Actions</li> <li>Pull requests are welcome</li> </ul>"},{"location":"api/","title":"SQLAlchemyCsvWriter API Reference","text":"<p>Write SQL Alchemy results to a csv file.</p> Source code in <code>sqlalchemy_csv_writer/writer.py</code> <pre><code>class SQLAlchemyCsvWriter:\n    \"\"\"Write SQL Alchemy results to a csv file.\"\"\"\n\n    def __init__(\n        self,\n        csvfile: Union[Path, str, typing.IO],\n        header: Union[list[str], bool] = True,\n        prefix_model_names: bool = False,\n        field_formats: Union[dict[str, str], None] = None,\n        dialect=\"excel\",\n        **fmtparams,\n    ):\n        \"\"\"Create a SQLAlchemyCsvWriter instance.\n\n        The instance's methods can be used to write rows to the specified csv file.\n\n        Args:\n            csvfile: Path or File-like object to write the resulting csv data to\n            header: True to automatically generate header, False to disable header or list of strings for custom header\n            prefix_model_names:  Whether to prefix the model names in the header\n            field_formats: Dictionary containing the column name as keys and column format as a values (using % style format syntax)\n            dialect: csv dialect to use\n            **fmtparams: extra formatting parameters to pass to csv.writer instance\n        \"\"\"\n        if isinstance(csvfile, str):\n            csvfile = Path(csvfile)\n        if isinstance(csvfile, Path):\n            csvfile.parent.mkdir(exist_ok=True, parents=True)\n            csvfile = open(csvfile, \"w\", encoding=\"utf-8\")  # noqa: SIM115\n\n        self.csvfile = csvfile\n        self.writer = csv.writer(csvfile, dialect=dialect, **fmtparams)\n        self.header = header\n        self.prefix_model_names = prefix_model_names\n        self.field_formats = field_formats if field_formats else {}\n        self.header_row_written = False\n\n    def __del__(self):\n        \"\"\"Close open resources.\"\"\"\n        if hasattr(self.csvfile, \"close\"):\n            self.csvfile.close()\n\n    def __enter__(self):\n        \"\"\"SQLAlchemyCsvWriter may be used as a context manager.\"\"\"\n        return self\n\n    def __exit__(self, type, value, traceback):\n        \"\"\"Exit context manager.\"\"\"\n        self.__del__()\n\n    async def write_rows_stream(self, results: list):\n        \"\"\"Write query results to csv.\n\n        Write query results retrieved with SQLAlchemy's .stream or .stream_scalars.\n\n        Args:\n            results: query results retrieved with SQLAlchemy's .stream or .stream_scalars\n        \"\"\"\n        async for result in results:\n            self._process_result(result)\n\n    def write_rows(self, results: list):\n        \"\"\"Write query results to csv.\n\n        Write query results retrieved with SQLAlchemy's .execute or .scalars. to csv\n\n        Args:\n            results: query results retrieved with SQLAlchemy's .execute or .scalars\n        \"\"\"\n        for result in results:\n            self._process_result(result)\n\n    def _process_result(self, result):\n        result = self._extract_columns(result)\n\n        # write header\n        if self.header and not self.header_row_written:\n            if self.header is True:\n                self.writer.writerow([r[0] for r in result])\n            else:\n                if len(self.header) == len(result):\n                    self.writer.writerow(self.header)\n                else:\n                    raise ValueError(\"Length of header and content does not match.\")\n            self.header_row_written = True\n\n        # write data\n        values = []\n        for key, value in result:\n            if str(key) in self.field_formats:\n                value = self.field_formats[str(key)] % value\n            values.append(value)\n        self.writer.writerow(values)\n\n    def _extract_columns(self, result):\n        columns = []\n        if hasattr(result, \"_mapping\"):  # is not a scalar\n            for element_key, element_value in result._mapping.items():\n                if isinstance(element_value, DeclarativeBase):  # is an orm model\n                    columns.extend(self._extract_model(element_value))\n                else:  # is a column\n                    columns.append((element_key, element_value))\n        elif isinstance(result, DeclarativeBase):  # is a scalar orm model\n            columns.extend(self._extract_model(result))\n\n        return columns\n\n    def _extract_model(self, obj):\n        insp = inspect(obj)\n        if self.prefix_model_names:\n            return [(getattr(insp.class_, attr.key), attr.value) for attr in insp.attrs]\n        else:\n            return [(attr.key, attr.value) for attr in insp.attrs]\n</code></pre>"},{"location":"api/#sqlalchemy_csv_writer.writer.SQLAlchemyCsvWriter.__enter__","title":"<code>__enter__()</code>","text":"<p>SQLAlchemyCsvWriter may be used as a context manager.</p> Source code in <code>sqlalchemy_csv_writer/writer.py</code> <pre><code>def __enter__(self):\n    \"\"\"SQLAlchemyCsvWriter may be used as a context manager.\"\"\"\n    return self\n</code></pre>"},{"location":"api/#sqlalchemy_csv_writer.writer.SQLAlchemyCsvWriter.__init__","title":"<code>__init__(csvfile, header=True, prefix_model_names=False, field_formats=None, dialect='excel', **fmtparams)</code>","text":"<p>Create a SQLAlchemyCsvWriter instance.</p> <p>The instance's methods can be used to write rows to the specified csv file.</p> <p>Parameters:</p> Name Type Description Default <code>csvfile</code> <code>Union[Path, str, IO]</code> <p>Path or File-like object to write the resulting csv data to</p> required <code>header</code> <code>Union[list[str], bool]</code> <p>True to automatically generate header, False to disable header or list of strings for custom header</p> <code>True</code> <code>prefix_model_names</code> <code>bool</code> <p>Whether to prefix the model names in the header</p> <code>False</code> <code>field_formats</code> <code>Union[dict[str, str], None]</code> <p>Dictionary containing the column name as keys and column format as a values (using % style format syntax)</p> <code>None</code> <code>dialect</code> <p>csv dialect to use</p> <code>'excel'</code> <code>**fmtparams</code> <p>extra formatting parameters to pass to csv.writer instance</p> <code>{}</code> Source code in <code>sqlalchemy_csv_writer/writer.py</code> <pre><code>def __init__(\n    self,\n    csvfile: Union[Path, str, typing.IO],\n    header: Union[list[str], bool] = True,\n    prefix_model_names: bool = False,\n    field_formats: Union[dict[str, str], None] = None,\n    dialect=\"excel\",\n    **fmtparams,\n):\n    \"\"\"Create a SQLAlchemyCsvWriter instance.\n\n    The instance's methods can be used to write rows to the specified csv file.\n\n    Args:\n        csvfile: Path or File-like object to write the resulting csv data to\n        header: True to automatically generate header, False to disable header or list of strings for custom header\n        prefix_model_names:  Whether to prefix the model names in the header\n        field_formats: Dictionary containing the column name as keys and column format as a values (using % style format syntax)\n        dialect: csv dialect to use\n        **fmtparams: extra formatting parameters to pass to csv.writer instance\n    \"\"\"\n    if isinstance(csvfile, str):\n        csvfile = Path(csvfile)\n    if isinstance(csvfile, Path):\n        csvfile.parent.mkdir(exist_ok=True, parents=True)\n        csvfile = open(csvfile, \"w\", encoding=\"utf-8\")  # noqa: SIM115\n\n    self.csvfile = csvfile\n    self.writer = csv.writer(csvfile, dialect=dialect, **fmtparams)\n    self.header = header\n    self.prefix_model_names = prefix_model_names\n    self.field_formats = field_formats if field_formats else {}\n    self.header_row_written = False\n</code></pre>"},{"location":"api/#sqlalchemy_csv_writer.writer.SQLAlchemyCsvWriter.write_rows","title":"<code>write_rows(results)</code>","text":"<p>Write query results to csv.</p> <p>Write query results retrieved with SQLAlchemy's .execute or .scalars. to csv</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>list</code> <p>query results retrieved with SQLAlchemy's .execute or .scalars</p> required Source code in <code>sqlalchemy_csv_writer/writer.py</code> <pre><code>def write_rows(self, results: list):\n    \"\"\"Write query results to csv.\n\n    Write query results retrieved with SQLAlchemy's .execute or .scalars. to csv\n\n    Args:\n        results: query results retrieved with SQLAlchemy's .execute or .scalars\n    \"\"\"\n    for result in results:\n        self._process_result(result)\n</code></pre>"},{"location":"api/#sqlalchemy_csv_writer.writer.SQLAlchemyCsvWriter.write_rows_stream","title":"<code>write_rows_stream(results)</code>  <code>async</code>","text":"<p>Write query results to csv.</p> <p>Write query results retrieved with SQLAlchemy's .stream or .stream_scalars.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>list</code> <p>query results retrieved with SQLAlchemy's .stream or .stream_scalars</p> required Source code in <code>sqlalchemy_csv_writer/writer.py</code> <pre><code>async def write_rows_stream(self, results: list):\n    \"\"\"Write query results to csv.\n\n    Write query results retrieved with SQLAlchemy's .stream or .stream_scalars.\n\n    Args:\n        results: query results retrieved with SQLAlchemy's .stream or .stream_scalars\n    \"\"\"\n    async for result in results:\n        self._process_result(result)\n</code></pre>"},{"location":"changelog/","title":"Release Notes","text":""},{"location":"changelog/#040","title":"0.4.0","text":"<ul> <li>measure coverage and add to docs</li> <li>adjust additional init parameters to match official csv.writer documentation</li> </ul>"},{"location":"changelog/#031","title":"0.3.1","text":"<ul> <li>add mkdocs and release to GitHub pages</li> </ul>"},{"location":"changelog/#030","title":"0.3.0","text":"<ul> <li>add support for passing string path or pathlib Path as csvfile parameter</li> <li>add support to use as context manager</li> </ul>"},{"location":"changelog/#020","title":"0.2.0","text":"<ul> <li>improve method naming</li> </ul>"},{"location":"changelog/#011","title":"0.1.1","text":"<ul> <li>fix minimum version requirement in pyprojects.toml</li> </ul>"},{"location":"changelog/#010","title":"0.1.0","text":"<ul> <li>initial release</li> </ul>"},{"location":"examples/example_async/","title":"Asynchronous usage","text":"<p>Usage with asynchronous SQLAlchemy - pass results of .execute and .scalars methods:</p> <pre><code>import asyncio\nfrom io import StringIO\n\nfrom alchemical.aio import Alchemical, Model\nfrom sqlalchemy import String, select\nfrom sqlalchemy.orm import Mapped, mapped_column\n\nfrom sqlalchemy_csv_writer import SQLAlchemyCsvWriter\n\n\nclass User(Model):\n    id: Mapped[int] = mapped_column(primary_key=True)\n    name: Mapped[str] = mapped_column(String(128))\n    value: Mapped[float] = mapped_column()\n\n\nasync def run():\n    db = Alchemical(\"sqlite:///:memory:\")\n    await db.drop_all()\n    await db.create_all()\n\n    async with db.begin() as session:\n        for name in [\"mary\", \"joe\", \"susan\"]:\n            session.add(User(name=name, value=12.3))\n\n    async with db.Session() as session:\n        stringio = StringIO()\n        results = await session.execute(select(User))\n\n        field_formats = {\"value\": \"%.2f\"}\n        writer = SQLAlchemyCsvWriter(\n            stringio,\n            header=True,\n            field_formats=field_formats,\n            dialect=\"unix\",\n        )\n        writer.write_rows(results)\n\n        print(stringio.getvalue())\n\n\nasyncio.run(run())\n</code></pre>"},{"location":"examples/example_async_stream/","title":"Asynchronous Streaming usage","text":"<p>Usage with asynchronous SQLAlchemy - pass results of .stream and .stream_scalars methods:</p> <pre><code>import asyncio\nfrom io import StringIO\n\nfrom alchemical.aio import Alchemical, Model\nfrom sqlalchemy import String, select\nfrom sqlalchemy.orm import Mapped, mapped_column\n\nfrom sqlalchemy_csv_writer import SQLAlchemyCsvWriter\n\n\nclass User(Model):\n    id: Mapped[int] = mapped_column(primary_key=True)\n    name: Mapped[str] = mapped_column(String(128))\n    value: Mapped[float] = mapped_column()\n\n\nasync def run():\n    db = Alchemical(\"sqlite:///:memory:\")\n    await db.drop_all()\n    await db.create_all()\n\n    async with db.begin() as session:\n        for name in [\"mary\", \"joe\", \"susan\"]:\n            session.add(User(name=name, value=12.3))\n\n    async with db.Session() as session:\n        stringio = StringIO()\n        results = await session.stream(select(User))\n\n        field_formats = {\"value\": \"%.2f\"}\n        writer = SQLAlchemyCsvWriter(\n            stringio,\n            header=True,\n            field_formats=field_formats,\n            dialect=\"unix\",\n        )\n        await writer.write_rows_stream(results)\n\n        print(stringio.getvalue())\n\n\nasyncio.run(run())\n</code></pre>"},{"location":"examples/example_sync/","title":"Synchronous Usage","text":"<p>Usage with synchronous SQLAlchemy - pass resuls of .execute and .scalars methods:</p> <pre><code>from pathlib import Path\n\nfrom alchemical import Alchemical, Model\nfrom sqlalchemy import String, select\nfrom sqlalchemy.orm import Mapped, mapped_column\n\nfrom sqlalchemy_csv_writer import SQLAlchemyCsvWriter\n\n\nclass User(Model):\n    id: Mapped[int] = mapped_column(primary_key=True)\n    name: Mapped[str] = mapped_column(String(128))\n    value: Mapped[float] = mapped_column()\n\n\ndb = Alchemical(\"sqlite:///:memory:\")\ndb.drop_all()\ndb.create_all()\n\nwith db.begin() as session:\n    for name in [\"mary\", \"joe\", \"susan\"]:\n        session.add(User(name=name, value=12.3))\n\nwith db.Session() as session:\n    results = session.execute(select(User)).all()\n\n    field_formats = {\"value\": \"%.2f\"}\n    with SQLAlchemyCsvWriter(\n        Path(\"test/example_sync.csv\"),\n        header=True,\n        field_formats=field_formats,\n        prefix_model_names=True,\n        dialect=\"unix\",\n    ) as writer:\n        writer.write_rows(results)\n</code></pre>"},{"location":"coverage/","title":"Coverage report","text":""}]}